

# --- Qatten specific parameters ---

# use epsilon greedy action selector
action_selector: "epsilon_greedy"
epsilon_start: 1.0
epsilon_finish: 0.05
epsilon_anneal_time: 50000

runner: "episode"

buffer_size: 5000

obs_agent_id: False
obs_last_action: False
obs_individual_obs: False

# update the target network every {} episodes
target_update_interval_or_tau: 0.1

# use the Q_Learner to train
mac: "non_shared_mac"
agent: "rnn_ns"
agent_output_type: "q"
learner: "dmaq_qatten_learner"
double_q: True
use_rnn: True
mixer: "dmaq"
mixing_embed_dim: 32
hypernet_embed: 64
adv_hypernet_layers: 3
adv_hypernet_embed: 64
evaluation_epsilon: 0.0
standardise_rewards: True

num_kernel: 10
is_minus_one: True
weighted_head: True
is_adv_attention: True
is_stop_gradient: True
t_max: 50500
test_interval: 2000 # Test after {} timesteps have passed
test_greedy: True # Use greedy evaluation (if False, will set epsilon floor to 0
log_interval: 2000
name: "qplex_ns"